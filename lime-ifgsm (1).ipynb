{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":28903,"sourceType":"datasetVersion","datasetId":22535},{"sourceId":7047846,"sourceType":"datasetVersion","datasetId":4055311}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scipy==1.10.1 scikit-image==0.19.3 vit_keras==0.1.2","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:44:02.155236Z","iopub.execute_input":"2023-12-08T14:44:02.155504Z","iopub.status.idle":"2023-12-08T14:44:13.698299Z","shell.execute_reply.started":"2023-12-08T14:44:02.155477Z","shell.execute_reply":"2023-12-08T14:44:13.696831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nfrom vit_keras import vit, utils\nimport lime\nimport skimage\nimport shap\nimport pandas as pd\nfrom sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\nfrom lime.lime_image import LimeImageExplainer","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:44:13.704345Z","iopub.execute_input":"2023-12-08T14:44:13.705058Z","iopub.status.idle":"2023-12-08T14:44:20.210283Z","shell.execute_reply.started":"2023-12-08T14:44:13.705023Z","shell.execute_reply":"2023-12-08T14:44:20.209405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/dogs-cats-images/dataset/training_set'\ntest_dir = '/kaggle/input/dogs-cats-images/dataset/test_set'\n\nclasses = os.listdir(train_dir)[0:2]\nclasses","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:44:20.211468Z","iopub.execute_input":"2023-12-08T14:44:20.212040Z","iopub.status.idle":"2023-12-08T14:44:20.267903Z","shell.execute_reply.started":"2023-12-08T14:44:20.212009Z","shell.execute_reply":"2023-12-08T14:44:20.267084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resize_size = 256\ncrop_size = 224\n\ndef preprocess_image(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = tf.image.resize(image, [resize_size, resize_size], method=tf.image.ResizeMethod.BILINEAR) #크기 조절\n    image = tf.image.central_crop(image, central_fraction=crop_size / resize_size) #중앙 224x224\n    image = tf.math.divide(image, 255.0) #normalize\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    image = (image - mean) / std #다 normalize\n\n    return image\n\n\ndef resize_and_crop(image, resize_size=256, crop_size=224):\n    # Resize with bilinear interpolation\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    resized_image = tf.image.resize(image, [resize_size, resize_size], method=tf.image.ResizeMethod.BILINEAR)\n    cropped_image = tf.image.central_crop(resized_image, central_fraction=crop_size / resize_size)\n    image = tf.math.divide(cropped_image, 255.0) #normalize\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:44:20.269522Z","iopub.execute_input":"2023-12-08T14:44:20.269791Z","iopub.status.idle":"2023-12-08T14:44:20.278287Z","shell.execute_reply.started":"2023-12-08T14:44:20.269768Z","shell.execute_reply":"2023-12-08T14:44:20.277339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index=0\ndf = pd.DataFrame(columns=['label', 'path', 'divide'])\nfor i in classes:\n    for data_dir in [train_dir, test_dir]:\n        folderPath = os.path.join(data_dir,i)\n        for j in tqdm(os.listdir(folderPath)):\n            df.loc[index]=[folderPath.split('/')[-1], folderPath+\"/\"+j, None]\n            index+=1\n            \nprint(df)\n\ntrain_df, xx = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(xx, test_size=0.5, random_state=42)\ntrain_df['divide'] = 'train'\nval_df['divide'] = 'validation'\ntest_df['divide'] = 'test'","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:47:00.523741Z","iopub.execute_input":"2023-12-08T14:47:00.524150Z","iopub.status.idle":"2023-12-08T14:47:11.230474Z","shell.execute_reply.started":"2023-12-08T14:47:00.524118Z","shell.execute_reply":"2023-12-08T14:47:11.229491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_df, val_df, test_df], ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:47:21.994805Z","iopub.execute_input":"2023-12-08T14:47:21.995200Z","iopub.status.idle":"2023-12-08T14:47:22.001692Z","shell.execute_reply.started":"2023-12-08T14:47:21.995168Z","shell.execute_reply":"2023-12-08T14:47:22.000659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('cat_dog_df.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=df[df['divide']=='test']\nX_test = []\ny_test = []\nOriginal_X = []\nfor i in range(len(test)):\n    img = cv2.imread(test['path'].iloc[i])\n    p_img = preprocess_image(img)\n    O_img = resize_and_crop(img)\n    Original_X.append(O_img)\n    X_test.append(p_img)\n    y_test.append(test['label'].iloc[i])\nX_test = np.array(X_test)\ny_test = np.array(y_test)\ny_test = tf.keras.utils.to_categorical([classes.index(label) for label in y_test])\nOriginal_X = np.array(Original_X)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:49:03.288773Z","iopub.execute_input":"2023-12-08T14:49:03.289577Z","iopub.status.idle":"2023-12-08T14:49:13.750953Z","shell.execute_reply.started":"2023-12-08T14:49:03.289528Z","shell.execute_reply":"2023-12-08T14:49:13.750058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name in ['vgg']:\n    model = keras.models.load_model('/kaggle/input/dog-and-cat-classifier/'+model_name+\"_best_model.h5\", compile=False)\n    model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n    y_pred = model.predict(X_test)\n    y_pred_single_label = np.argmax(y_pred, axis=1)\n    y_test_single_label = np.argmax(y_test, axis=1)\n    precision = precision_score(y_test_single_label, y_pred_single_label, average='macro')\n    recall = recall_score(y_test_single_label, y_pred_single_label, average='macro')\n    f1 = f1_score(y_test_single_label, y_pred_single_label, average='macro')\n    accuracy = accuracy_score(y_test_single_label, y_pred_single_label)\n    precision = round(precision, 3)\n    recall = round(recall, 3)\n    f1 = round(f1, 3)\n    accuracy = round(accuracy, 3)\n    print(str(model_name))\n    print(model_name, \":\", precision, recall, f1, accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:49:19.670721Z","iopub.execute_input":"2023-12-08T14:49:19.671136Z","iopub.status.idle":"2023-12-08T14:49:26.242392Z","shell.execute_reply.started":"2023-12-08T14:49:19.671104Z","shell.execute_reply":"2023-12-08T14:49:26.241384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [] #Image\ny = [] #class\n#Original_X = []\nfor i in classes:\n    for data_dir in [train_dir, test_dir]:\n        folderPath = os.path.join(data_dir,i)\n        for j in tqdm(os.listdir(folderPath)):\n            img = cv2.imread(os.path.join(folderPath,j))\n            O_img = resize_and_crop(img)\n            #Original_X.append(O_img)\n            img = preprocess_image(img)\n            X.append(img)\n            y.append(i)\nX = np.array(X)\ny = np.array(y)\ny = tf.keras.utils.to_categorical([classes.index(label) for label in y])\n#Original_X = np.array(Original_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name in ['vgg']:\n    model = keras.models.load_model('/kaggle/input/dog-and-cat-classifier/'+model_name+\"_best_model.h5\", compile=False)\n    model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n    X_train,xx,y_train,yy = train_test_split(X, y, test_size=0.2,random_state=42)\n    X_val,X_test,y_val,y_test = train_test_split(xx, yy, test_size=0.5,random_state=42)\n    y_pred = model.predict(X_test)\n    y_pred_single_label = np.argmax(y_pred, axis=1)\n    y_test_single_label = np.argmax(y_test, axis=1)\n    precision = precision_score(y_test_single_label, y_pred_single_label, average='macro')\n    recall = recall_score(y_test_single_label, y_pred_single_label, average='macro')\n    f1 = f1_score(y_test_single_label, y_pred_single_label, average='macro')\n    accuracy = accuracy_score(y_test_single_label, y_pred_single_label)\n    precision = round(precision, 3)\n    recall = round(recall, 3)\n    f1 = round(f1, 3)\n    accuracy = round(accuracy, 3)\n    print(str(model_name))\n    print(model_name, \":\", precision, recall, f1, accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\n\ndef save_and_close_figure(image, save_path, index_to_use, predicted_class, real):\n    plt.imshow(image)\n    plt.axis('off')\n    plt.savefig(os.path.join(save_path, f'{index_to_use}_predict_{predicted_class}_real_{real}.jpg'), bbox_inches='tight', pad_inches=0)\n    plt.close('all')\n\n    \ndef plot_images(original, temp, mask, model_name, model_type, index_to_use, predicted_class, real):\n    \n    save_paths = [f'{model_name}/{model_type}/original/', f'{model_name}/{model_type}/superpixel/', f'{model_name}/{model_type}/pos_neg/']\n    \n    for save_path in save_paths:\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n\n    save_and_close_figure(original, f'{model_name}/{model_type}/original/', index_to_use, predicted_class, real)\n    \n    # Lime Mask를 원본 이미지에 적용하여 긍부정 시각화\n    masked_positive = np.copy(original)\n    masked_positive = np.concatenate((masked_positive, np.ones((*masked_positive.shape[:-1], 1), dtype=masked_positive.dtype) * 255), axis=-1)  # Add alpha channel\n    masked_positive[mask <= 0, -1] = 0\n    \n    save_and_close_figure(masked_positive, f'{model_name}/{model_type}/superpixel/', index_to_use, predicted_class, real)\n\n    # Lime Mask를 원본 이미지에 적용하여 긍부정 시각화\n    masked_negative = np.zeros_like(original)\n    masked_negative[mask < 0] = [255, 0, 0]\n\n    # Create a new image for positive parts (green color)\n    masked_positive = np.zeros_like(original)\n    masked_positive[mask > 0] = [0, 255, 0]\n\n    # Combine the positive and negative images\n    combined_image = original + masked_negative + masked_positive\n\n    # Display the result with larger size\n    save_and_close_figure(combined_image, f'{model_name}/{model_type}/pos_neg/', index_to_use, predicted_class, real)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:49:34.440341Z","iopub.execute_input":"2023-12-08T14:49:34.441220Z","iopub.status.idle":"2023-12-08T14:49:34.451972Z","shell.execute_reply.started":"2023-12-08T14:49:34.441183Z","shell.execute_reply":"2023-12-08T14:49:34.450942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport io\nfor index_to_use in range(50):\n    selected_image = X_test[index_to_use]\n    selected_image = np.expand_dims(selected_image, axis=0)\n    prediction = model.predict(selected_image)\n    predicted_class = np.argmax(prediction)\n    real = np.argmax(y_test[index_to_use])\n    original_stdout = sys.stdout\n    sys.stdout = io.StringIO()\n    explainer = lime.lime_image.LimeImageExplainer(feature_selection='auto')\n    explanation = explainer.explain_instance(selected_image[0], model.predict, top_labels=1, hide_color=0, num_samples=100)\n    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n    sys.stdout = original_stdout\n    plot_images(Original_X[index_to_use], temp, mask, model_name, 'base_model', index_to_use, predicted_class, real)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:49:35.742071Z","iopub.execute_input":"2023-12-08T14:49:35.742785Z","iopub.status.idle":"2023-12-08T14:50:20.025024Z","shell.execute_reply.started":"2023-12-08T14:49:35.742750Z","shell.execute_reply":"2023-12-08T14:50:20.023914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_for_attack(image):\n    #resize, crop까지는 이미 이전 과정에서 진행했으므로\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    image = (image - mean) / std #다 normalize\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:50:41.970774Z","iopub.execute_input":"2023-12-08T14:50:41.971199Z","iopub.status.idle":"2023-12-08T14:50:41.976306Z","shell.execute_reply.started":"2023-12-08T14:50:41.971168Z","shell.execute_reply":"2023-12-08T14:50:41.975488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ifgsm_attack(model, image, label, epsilon=0.001, num_iter=30, clip_min=0.0, clip_max=1.0):\n    adv_image = tf.identity(image)\n    for _ in range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(adv_image)\n            prediction = model(preprocess_for_attack(adv_image))\n            loss = tf.keras.losses.sparse_categorical_crossentropy(label, prediction)\n\n        gradient = tape.gradient(loss, adv_image)\n        perturbation = epsilon * tf.sign(gradient)\n\n        adv_image = tf.clip_by_value(adv_image + perturbation, clip_min, clip_max)\n\n    adv_image_np = adv_image.numpy().squeeze()  # Squeeze to remove channel dimension\n\n    # Lime explanation\n    original_stdout = sys.stdout\n    sys.stdout = io.StringIO()\n\n    explainer = lime.lime_image.LimeImageExplainer(feature_selection='auto')\n    explanation = explainer.explain_instance(adv_image_np, model.predict, top_labels=1, hide_color=0, num_samples=100)\n    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n\n    sys.stdout = original_stdout\n    \n    # Assuming you have model_name, index_to_use, predicted_class, real defined somewhere\n    plot_images(adv_image.numpy().squeeze(), temp, mask, model_name, 'adv', index_to_use, np.argmax(prediction), label)\n\n    return adv_image, prediction","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:50:43.603582Z","iopub.execute_input":"2023-12-08T14:50:43.604478Z","iopub.status.idle":"2023-12-08T14:50:43.613278Z","shell.execute_reply.started":"2023-12-08T14:50:43.604442Z","shell.execute_reply":"2023-12-08T14:50:43.612661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Le, L. D., Fu, H., Xu, X., Liu, Y., Xu, Y., Du, J., ... & Goh, R. (2022, September). An Efficient Defending Mechanism Against Image Attacking on Medical Image Segmentation Models. In MICCAI Workshop on Resource-Efficient Medical Image Analysis (pp. 65-74). Cham: Springer Nature Switzerland.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_paths = [f'{model_name}/adv/attack/']\nfor save_path in save_paths:\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n            \nfor index_to_use in range(len(X_test)):\n    selected_image = X_test[index_to_use]\n    selected_image = np.expand_dims(selected_image, axis=0)\n    prediction = model.predict(selected_image)\n    predicted_class = np.argmax(prediction)\n    real_class = np.argmax(y_test[index_to_use])\n    preprocess_input = tf.keras.applications.vgg16.preprocess_input\n\n    image = Original_X[index_to_use]\n    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n    label = np.argmax(y_test[index_to_use])\n\n    original_prediction = model(preprocess_for_attack(image))\n    adv_image, adv_prediction = ifgsm_attack(model, image, label)\n\n    # Extract top-1 predictions\n    original_top1_class = tf.argmax(original_prediction, axis=1)[0:5]\n    adv_top1_class = tf.argmax(adv_prediction, axis=1)[0:5]\n    \n    save_and_close_figure(adv_image.numpy().squeeze(), f'{model_name}/adv/attack/', index_to_use, {adv_top1_class[0]}, real_class)\n    \n'''\n    # Display the results\n    plt.figure(figsize=(15, 6))\n    plt.subplot(1, 4, 1)\n    plt.imshow(image.numpy().squeeze())\n    plt.title('Original Image')\n\n    plt.subplot(1, 4, 2)\n    plt.text(0, 0.5, f'Top-1 Prediction: Class {original_top1_class}', fontsize=12)\n    plt.axis('off')\n\n    plt.subplot(1, 4, 3)\n    plt.imshow(adv_image.numpy().squeeze())\n    plt.title('Adversarial Image')\n\n    plt.subplot(1, 4, 4)\n    plt.text(0, 0.5, f'Top-1 Prediction: Class {adv_top1_class}', fontsize=12)\n    plt.axis('off')\n    plt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:51:18.324521Z","iopub.execute_input":"2023-12-08T14:51:18.325540Z","iopub.status.idle":"2023-12-08T14:51:25.700234Z","shell.execute_reply.started":"2023-12-08T14:51:18.325501Z","shell.execute_reply":"2023-12-08T14:51:25.699106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nfrom IPython.display import FileLink\n\n# Change the current working directory to '/kaggle/working'\nos.chdir('/kaggle/working')\n\n# Define the name of the tar.gz archive\narchive_name = 'kaggle_working.tar.gz'\n\n# Create a tar.gz archive of the entire directory\nshutil.make_archive(archive_name.replace('.tar.gz', ''), 'gztar', root_dir='.', base_dir='.')\n\n# Display the link to download the archive\nFileLink(archive_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}